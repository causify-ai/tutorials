{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e5053c0-9a04-4d4b-af6a-6964d84c1f65",
   "metadata": {},
   "source": [
    "# LangChain API Tutorial\n",
    "\n",
    "This tutorial demonstrates how to use LangChain's core functionalities.\n",
    "LangChain is a powerful framework designed to facilitate building language model-powered applications.\n",
    "We'll explore its components, including prompt creation, chains, retrieval, and agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37718519",
   "metadata": {},
   "source": [
    "## Setting Up\n",
    "\n",
    "We'll start by setting up the environment and initializing our language model (`ChatOpenAI`).\n",
    "Here, we're using OpenAI's `gpt-4o-mini` model with a temperature of 0 for deterministic outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d3cf220-31e0-4782-b66d-9df5d10685bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import langchain as lnch\n",
    "import langchain.schema.messages as lnchscme\n",
    "# Install necessary package\n",
    "#!pip install --quiet chromadb\n",
    "\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import helpers.hdbg as hdbg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efcb5daf-ebf6-4574-8037-eeb7222b580d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mWARNING: Running in Jupyter\n",
      "INFO  > cmd='/venv/lib/python3.12/site-packages/ipykernel_launcher.py -f /home/.local/share/jupyter/runtime/kernel-5dfc3c77-eff9-496b-989a-16c5816a8c19.json'\n"
     ]
    }
   ],
   "source": [
    "hdbg.init_logger(verbosity=logging.INFO)\n",
    "\n",
    "_LOG = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5e73ca7-6473-4abe-b903-8036d2099256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"  # Replace with your actual API key\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ea58a6",
   "metadata": {},
   "source": [
    "## Message Handling with `HumanMessage` and `SystemMessage`\n",
    "\n",
    "LangChain uses `HumanMessage` and `SystemMessage` objects to structure conversations.\n",
    "- **`SystemMessage`**: Defines the behavior of the assistant.\n",
    "- **`HumanMessage`**: Represents user input.\n",
    "\n",
    "Let's see how this works in practice with some example messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59dc1486-f47f-462f-a507-219137b443ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Define system behavior and user input.\n",
    "messages = [\n",
    "    SystemMessage(content=\"You're an assistant knowledgeable about healthcare.\"),\n",
    "    HumanMessage(content=\"What is Medicaid managed care?\")\n",
    "]\n",
    "# Generate a response.\n",
    "chat_model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc351315",
   "metadata": {},
   "source": [
    "## Restricting Assistant's Scope\n",
    "\n",
    "You can further control the assistant's responses by tailoring the `SystemMessage`.\n",
    "For instance, we'll restrict it to only answer healthcare-related questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccc34d4c-72df-4be5-97a9-f201d334524c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm here to help with healthcare-related questions. If you have any health-related inquiries, feel free to ask!\")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You're an assistant knowledgeable about healthcare. Only answer healthcare-related questions.\"),\n",
    "    HumanMessage(content=\"How do I change a tire?\")\n",
    "]\n",
    "chat_model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d825081",
   "metadata": {},
   "source": [
    "## Creating Custom Prompts with `ChatPromptTemplate`\n",
    "\n",
    "Custom prompts are essential for tasks like summarization, question answering, or content generation.\n",
    "We'll use `ChatPromptTemplate` to define structured prompts and format them dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1916da5-713c-4c19-827f-d700319cb3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Your job is to use patient\n",
      "reviews to answer questions about their experience at a hospital.\n",
      "Use the following context to answer questions. Be as detailed\n",
      "as possible, but don't make up any information that's not\n",
      "from the context. If you don't know an answer, say you don't know.\n",
      "\n",
      "I had a great stay!\n",
      "\n",
      "Did anyone have a positive experience?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Define a custom template for hospital reviews\n",
    "review_template_str = \"\"\"\n",
    "Your job is to use patient reviews to answer questions about their experience at a hospital.\n",
    "Use the following context to answer questions. Be as detailed as possible, but don't make up\n",
    "any information that's not from the context. If you don't know an answer, say you don't know.\n",
    "\n",
    "{context}\n",
    "\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "review_template = ChatPromptTemplate.from_template(review_template_str)\n",
    "\n",
    "# Provide context and a question\n",
    "context = \"I had a great stay!\"\n",
    "question = \"Did anyone have a positive experience?\"\n",
    "\n",
    "# Format the template\n",
    "print(review_template.format(context=context, question=question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9685209",
   "metadata": {},
   "source": [
    "## Advanced Prompt Structuring\n",
    "\n",
    "Sometimes, you may need to structure prompts with multiple components, like system instructions and user input.\n",
    "`SystemMessagePromptTemplate` and `HumanMessagePromptTemplate` allow fine-grained control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3217aad3-3b15-4d2c-93f3-5194493ef5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content=\"Your job is to use patient\\nreviews to answer questions about their experience at a\\nhospital. Use the following context to answer questions.\\nBe as detailed as possible, but don't make up any information\\nthat's not from the context. If you don't know an answer, say\\nyou don't know.\\n\\nI had a great stay!\\n\"), HumanMessage(content='Did anyone have a positive experience?')]\n"
     ]
    }
   ],
   "source": [
    "# Define system and human message templates.\n",
    "review_system_prompt = SystemMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(input_variables=[\"context\"], template=review_template_str)\n",
    ")\n",
    "\n",
    "review_human_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(input_variables=[\"question\"], template=\"{question}\")\n",
    ")\n",
    "\n",
    "# Combine into a chat prompt template.\n",
    "review_prompt_template = ChatPromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    messages=[review_system_prompt, review_human_prompt]\n",
    ")\n",
    "\n",
    "# Format messages.\n",
    "formatted_messages = review_prompt_template.format_messages(context=context, question=question)\n",
    "print(formatted_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db841519-c997-4d8a-969b-88fc094d03aa",
   "metadata": {},
   "source": [
    "## Chains\n",
    "\n",
    "Chains are a fundamental abstraction in LangChain, allowing you to combine prompts and models into workflows.\n",
    "We'll create a simple chain to answer questions based on a given context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2db8f73-e443-400b-996b-8b7865fa7de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Create a chain using the template and chat model\n",
    "output_parser = StrOutputParser()\n",
    "review_chain = review_prompt_template | chat_model | output_parser\n",
    "\n",
    "# Test the chain\n",
    "review_chain.invoke({\"context\": context, \"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2999afc",
   "metadata": {},
   "source": [
    "## Retrieval with FAISS\n",
    "\n",
    "FAISS (Facebook AI Similarity Search) is used to efficiently retrieve relevant documents based on similarity scores.\n",
    "We'll demonstrate how to load a dataset, create embeddings, and retrieve documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4eca8f64-fd83-41f5-ae96-d2c25f41da5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, the patient had a great stay at the hospital, indicating a positive experience.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "REVIEWS_CSV_PATH = \"build_LLM_RAG_chatbot_with_langchain/reviews.csv\"\n",
    "REVIEWS_CHROMA_PATH = \"chroma_data\"\n",
    "\n",
    "# Load reviews dataset\n",
    "loader = CSVLoader(file_path=REVIEWS_CSV_PATH, source_column=\"review\")\n",
    "reviews = loader.load()\n",
    "\n",
    "# Create a vector store\n",
    "reviews_vector_db = Chroma.from_documents(reviews, OpenAIEmbeddings(), persist_directory=REVIEWS_CHROMA_PATH)\n",
    "\n",
    "# Retrieve relevant documents\n",
    "question = \"Has anyone complained about communication with the hospital staff?\"\n",
    "relevant_docs = reviews_vector_db.similarity_search(question, k=3)\n",
    "\n",
    "print(relevant_docs[0].page_content)\n",
    "print(relevant_docs[1].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a5db6e-b21b-40d8-8416-a4b367d7590f",
   "metadata": {},
   "source": [
    "## Building a Retrieval-Enhanced QA Chain\n",
    "\n",
    "We'll combine retrieval and prompts to build a more dynamic question-answering system.\n",
    "This chain retrieves relevant documents and uses them as context for the assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21d1b143-17c9-4b58-befa-a2f69257e374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "# Create a retriever\n",
    "reviews_retriever = reviews_vector_db.as_retriever(k=10)\n",
    "\n",
    "# Build the QA chain\n",
    "review_chain = (\n",
    "    {\"context\": reviews_retriever, \"question\": RunnablePassthrough()}\n",
    "    | review_prompt_template\n",
    "    | chat_model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Test the QA chain\n",
    "question = \"Has anyone complained about communication with the hospital staff?\"\n",
    "review_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9988de7a",
   "metadata": {},
   "source": [
    "## Agents\n",
    "\n",
    "Agents are more flexible than chains, as they can decide the sequence of actions to take.\n",
    "We'll demonstrate an agent that can answer questions using tools for reviews and wait times.\n",
    "\n",
    "- The chain is hardwired\n",
    "- An agent is an LLM that decides the sequence of actions to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eb98d4ac-8727-45f6-992d-4513d9714d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "def get_current_wait_time(hospital: str) -> int | str:\n",
    "    \"\"\"Dummy function to generate fake wait times\"\"\"\n",
    "\n",
    "    if hospital not in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "        return f\"Hospital {hospital} does not exist\"\n",
    "\n",
    "    # Simulate API call delay\n",
    "    time.sleep(1)\n",
    "\n",
    "    return random.randint(0, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b812a5c8-03db-4cbd-b7e3-c553933bb27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import (\n",
    "    create_openai_functions_agent,\n",
    "    Tool,\n",
    "    AgentExecutor,\n",
    ")\n",
    "from langchain import hub\n",
    "\n",
    "# Tool is an interface that an agent uses to interact with a function.\n",
    "# Each description explains the Agent when to call each tool.\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Reviews\",\n",
    "        func=review_chain.invoke,\n",
    "        description=\"\"\"Useful when you need to answer questions\n",
    "        about patient reviews or experiences at the hospital.\n",
    "        Not useful for answering questions about specific visit\n",
    "        details such as payer, billing, treatment, diagnosis,\n",
    "        chief complaint, hospital, or physician information.\n",
    "        Pass the entire question as input to the tool. For instance,\n",
    "        if the question is \"What do patients think about the triage system?\",\n",
    "        the input should be \"What do patients think about the triage system?\"\n",
    "        \"\"\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Waits\",\n",
    "        func=get_current_wait_time,\n",
    "        description=\"\"\"Use when asked about current wait times\n",
    "        at a specific hospital. This tool can only get the current\n",
    "        wait time at a hospital and does not have any information about\n",
    "        aggregate or historical wait times. This tool returns wait times in\n",
    "        minutes. Do not pass the word \"hospital\" as input,\n",
    "        only the hospital name itself. For instance, if the question is\n",
    "        \"What is the wait time at hospital A?\", the input should be \"A\".\n",
    "        \"\"\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "hospital_agent_prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "\n",
    "agent_chat_model = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "hospital_agent = create_openai_functions_agent(\n",
    "    llm=agent_chat_model,\n",
    "    prompt=hospital_agent_prompt,\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "# Agent run-time.\n",
    "hospital_agent_executor = AgentExecutor(\n",
    "    agent=hospital_agent,\n",
    "    tools=tools,\n",
    "    return_intermediate_steps=True,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a20f6d8e-f7f9-4237-97e9-b8dcc25cbe2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Waits` with `C`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m833\u001b[0m\u001b[32;1m\u001b[1;3mThe current wait time at hospital C is 833 minutes.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the current wait time at hospital C?',\n",
       " 'output': 'The current wait time at hospital C is 833 minutes.',\n",
       " 'intermediate_steps': [(AgentActionMessageLog(tool='Waits', tool_input='C', log='\\nInvoking: `Waits` with `C`\\n\\n\\n', message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"__arg1\":\"C\"}', 'name': 'Waits'}})]),\n",
       "   833)]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hospital_agent_executor.invoke(\n",
    "    {\"input\": \"What is the current wait time at hospital C?\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c53094d4-5868-4085-9ca5-95379954338c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Reviews` with `What have patients said about their comfort at the hospital?`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPatients have mentioned that the hospital staff is dedicated to patient care, but they have also expressed discomfort due to the uncomfortable beds, making it difficult to get a good night's sleep during their stay.\u001b[0m\u001b[32;1m\u001b[1;3mPatients have mentioned that the hospital staff is dedicated to patient care, but they have also expressed discomfort due to the uncomfortable beds, making it difficult to get a good night's sleep during their stay.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What have patients said about their comfort at the hospital?',\n",
       " 'output': \"Patients have mentioned that the hospital staff is dedicated to patient care, but they have also expressed discomfort due to the uncomfortable beds, making it difficult to get a good night's sleep during their stay.\",\n",
       " 'intermediate_steps': [(AgentActionMessageLog(tool='Reviews', tool_input='What have patients said about their comfort at the hospital?', log='\\nInvoking: `Reviews` with `What have patients said about their comfort at the hospital?`\\n\\n\\n', message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"__arg1\":\"What have patients said about their comfort at the hospital?\"}', 'name': 'Reviews'}})]),\n",
       "   \"Patients have mentioned that the hospital staff is dedicated to patient care, but they have also expressed discomfort due to the uncomfortable beds, making it difficult to get a good night's sleep during their stay.\")]}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hospital_agent_executor.invoke(\n",
    "    {\"input\": \"What have patients said about their comfort at the hospital?\"}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
